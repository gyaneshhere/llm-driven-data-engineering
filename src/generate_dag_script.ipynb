{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468475f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from util import get_api_key\n",
    "openai.api_key = get_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_files = os.listdir('../schemas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee44310",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schemas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in schema_files:\n",
    "    opened_file = open('../schemas/' + file, 'r')\n",
    "    all_schemas[file] = opened_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9998860",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "            You are a data engineer looking to generate an Airflow pipeline DAG skeleton \n",
    "            without the SQL details\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363bcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"\n",
    "                Generate a cumulative Airflow DAG that transforms \n",
    "                {all_schemas['player_seasons.sql']}\n",
    "                into {all_schemas['players.sql']}\n",
    "                use markdown for output and Postgres for queries\n",
    "                The DAG depends on last season data from players table \n",
    "                and the DAG depends on past is true\n",
    "                Make sure each run scans only one season and does a \n",
    "                FULL OUTER JOIN with the previous seasons data\n",
    "                Use the {{ ds }} airflow parameter to filter season \n",
    "                All create table statements should include IF NOT EXISTS\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(system_prompt)\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "answer = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.mkdir('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e78c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = filter(lambda x: x.startswith('python'), answer.split('```'))\n",
    "# Open the file with write permissions\n",
    "with open('output/airflow_dag.py', 'w') as file:\n",
    "    # Write some data to the file\n",
    "    file.write('\\n'.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3693f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
